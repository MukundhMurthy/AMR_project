python ../trainer/transformer.py \
    --batch_size 16 \
    --hidden 16 \
    --embed_dim 16 \
    --heads 1 \
    --depth 1 \
    --drop_prob 0 \
    --learning_rate 1e-2 \
    --epochs 2 \
    --model_type attention \
    --lr_scheduler plateau \
    --within_epoch_interval 5 \
    --patience 1 \
    --name_run first_trial \
    --split_method random \
    --manual_seed 42 \
    --num_workers 0 \
    --wandb
